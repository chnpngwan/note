## 1.内容回顾

|-- 创建虚拟机，机器名102
  |-- jdk的压缩包 /opt/software目录下
  |-- jdk的解压后 /opt/module目录下
  |-- 配置JAVA_HOME的环境变量

```properties
|-- /etc/profile 文件，是Linux系统的环境变量配置文件
|-- /etc/profile.d目录下，创建自己的shell脚本文件 my_evn.sh
  |-- JAVA_HOME配置在 my_evn.sh
  |-- /etc/profile 文件，自动读取profile.d目录下的shell脚本文件
|-- 生效环境变量：source /etc/profile
```

  |-- hadoop的压缩包 /opt/software目录下 
  |-- hadoop的解压后 /opt/module目录下
  |-- 配置HADOOP_HOME环境变量
​    |-- 配置方式和JDK一样
​    |-- hadoop环境变量要配置两个目录,bin,sbin

  |-- hadoop组成部分
​    |-- hdfs -- hadoop 分布式文件系统
​      |-- namenode服务：存储文件的元数据信息
​        |-- 文件名，大小，创建时间，块信息，hdfs中的存储位置

      |-- datanode服务：存储文件的，文件切割，最大存储块128MB
        |-- 多机器存储，搭建集群环境，一个文件在所有的机器都存储
    
      |-- secondarynamenode服务:备份元数据的服务

|-- **yarn -- 资源调度平台**
  |-- yarn 就是Java写好的mapreduce程序的运行平台
  |-- 负责分配内存，分配CPU
  |-- resourcemanager服务，所有yarn服务的总头领
    |-- nodemanager 真正的程序运行平台

|-- mapreduce -- java写的程序

## 2. 集群资料准备：scp 文件分发

- 需求：scp命令，将102机器的内容发送到103,104
  - 102机器：/opt/module 解压后的内容 jdk hadoop
  - 发到103和104，目录一致性

```properties
scp命令发送：scp -r 要发送的内容 另一台机器的用户名@主机名:要发送到的位置
```

- scp命令，将102机器的jdk（解压缩后的）发到103机器 （推送）

```properties
scp -r jdk1.8.0_212 atguigu@hadoop103:/opt/module/
```

- scp命令，在103机器，从102机器上拉取hadoop的解压后 （拉取）
  - 发送之间，建议删除102机器，hadoop解压目录/share/doc目录

```properties
        数据源机器用户名@机器名 数据源路径名             拉取到的位置
scp -r atguigu@hadoop102:/opt/module/hadoop-3.1.3 /opt/module/
```

- scp命令，在103机器，从102机器上拉取jdk，推送到104机器

```properties
        数据源机器:数据源路径                  目标机器：目标机路径
scp -r hadoop102:/opt/module/jdk1.8.0_212 hadoop104:/opt/module/
scp -r hadoop102:/opt/module/hadoop-3.1.3 hadoop104:/opt/module/
#如果不写登录其他机器的用户名，默认使用当前机器的登录名，当前103机器登录的用户名
```

> 注意：执行scp命令的时候，无论是数据源机器，还是目标机器，都不要操作，等文件传递完毕在操作

- rsync命令：机器之间的文件传递，做差异化传输，已经存在的文件，不在复制了

```
rsync命令：将102机器上的/opt/module所有内容，传递到103机器，差异化复制
```

## 3.同步环境变量

将102机器上：/etc/profile.d目录下的文件my_env.sh，同步到103和104机器上。

> 注意问题：同步103和104保证 my_env.sh 存储位置必须是/etc/profile.d

```properties
#执行失败 scp: /etc/profile.d/my_env.sh: Permission denied 权限不足
scp -r my_env.sh hadoop103:/etc/profile.d
同步103机器，登录103机器是root账户
scp -r my_env.sh root@hadoop103:/etc/profile.d
scp -r my_env.sh root@hadoop104:/etc/profile.d
目标机器加载环境变量配置文件：source /etc/profile
```

![](https://gitee.com/chnpngwng/typora-image/raw/master/assets/note/05281.png)

## 4. 服务器集群分发文件，shell脚本

scp命令可以实现机器之间的文件分发，机器数量大，造成有些机器没有发，有些机器发了，人的工作量就机器强大，因此定义shell脚本代码，同一发送，集群分发。

shell脚本：目的是在集群中做文件分发，102机器为数据源机器，发送/opt目录下的内容，也可能会发送/etc/profile.d目录的内容。

> 要求：群发的shell脚本文件可以在任意路径下之间，shell脚本文件放在哪里就很关键，shell代码放在自己的账户目录的bin下面

![](https://gitee.com/chnpngwng/typora-image/raw/master/assets/note/05282.png)

- xsync.sh

```shell
#!/bin/bash
#1. 判断参数个数
if [ $# -lt 1 ]
then
  echo Not Enough Arguement!
  exit;
fi
#2. 遍历集群所有机器
for host in hadoop103 hadoop104
do
  echo ====================  $host  ====================
  #3. 遍历所有目录，挨个发送
  for file in $@
  do
    #4. 判断文件是否存在
    if [ -e $file ]
    then
      #5. 获取父目录
      pdir=$(cd -P $(dirname $file); pwd)
      #6. 获取当前文件的名称
      fname=$(basename $file)
      ssh $host "mkdir -p $pdir"
      rsync -av $pdir/$fname $host:$pdir
    else
      echo $file does not exists!
    fi
  done
done

```

## 5.SSH安全外壳协议

SSH安全外壳协议目的免密登录：102,103,104 机器之间无论是谁连接谁都不在需要密码确认。

![](https://gitee.com/chnpngwng/typora-image/raw/master/assets/note/05283.png)

- 在102机器，产生ssh协议的密钥对（公钥，私有）

```properties
ssh-keygen -t rsa
密钥对产生位置：账户目录
id_rsa 私钥
id_rsa.pub 公钥
```

- 102机器，将公钥授权给103机器，104机器

```properties
ssh-copy-id hadoop103
ssh-copy-id hadoop104
ssh-copy-id hadoop102 给自己也授权
```

- 在103机器，产生ssh协议密钥对

```properties
ssh-keygen -t rsa
密钥对产生位置：账户目录
id_rsa 私钥
id_rsa.pub 公钥
```

- 在103机器，将公钥授权给102机器，104机器

```properties
ssh-copy-id hadoop103
ssh-copy-id hadoop104
ssh-copy-id hadoop102 给自己也授权
```

- 在104机器，产生ssh协议的密钥对（公钥，私有）
- 在104机器，将公钥授权给102机器，103机器

## 6. 集群配置文件分发

每台Hadoop服务器任务：节约内存，保证数据安全

|      |      hadoop102      |           hadoop103           |          hadoop104           |
| ---- | :-----------------: | :---------------------------: | :--------------------------: |
| HDFS | NameNode   DataNode |           DataNode            | SecondaryNameNode   DataNode |
| YARN |     NodeManager     | ResourceManager   NodeManager |         NodeManager          |

- 配置文件：在102机器中配置，分发到103,104机器

- Hadoop的用户配置文件：/opt/module/hadoop-3.1.3/etc/hadoop

  - core-site.xml 核心配置文件

  ```xml
  <configuration>
  	<!-- 指定NameNode的地址 -->
      <property>
          <name>fs.defaultFS</name>
          <value>hdfs://hadoop102:9820</value>
      </property>
  <!-- 指定hadoop数据的存储目录 -->
      <property>
          <name>hadoop.tmp.dir</name>
          <value>/opt/module/hadoop-3.1.3/data</value>
  </property>
  
  <!-- 配置HDFS网页登录使用的静态用户为atguigu -->
      <property>
          <name>hadoop.http.staticuser.user</name>
          <value>atguigu</value>
  </property>
  
  <!-- 配置该atguigu(superUser)允许通过代理访问的主机节点 -->
      <property>
          <name>hadoop.proxyuser.atguigu.hosts</name>
          <value>*</value>
  </property>
  <!-- 配置该atguigu(superUser)允许通过代理用户所属组 -->
      <property>
          <name>hadoop.proxyuser.atguigu.groups</name>
          <value>*</value>
  </property>
  <!-- 配置该atguigu(superUser)允许通过代理的用户-->
      <property>
          <name>hadoop.proxyuser.atguigu.users</name>
          <value>*</value>
  </property>
  
  </configuration>
  
  ```

  - hdfs-site.xml

  ```xml
  <configuration>
  	<!-- nn web端访问地址-->
  	<property>
          <name>dfs.namenode.http-address</name>
          <value>hadoop102:9870</value>
      </property>
  	<!-- 2nn web端访问地址-->
      <property>
          <name>dfs.namenode.secondary.http-address</name>
          <value>hadoop104:9868</value>
      </property>
  </configuration>
  
  ```

  - yarn-site.xml

  ```xml
  <?xml version="1.0" encoding="UTF-8"?>
  <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
  
  <configuration>
  	<!-- 指定MR走shuffle -->
      <property>
          <name>yarn.nodemanager.aux-services</name>
          <value>mapreduce_shuffle</value>
  </property>
  <!-- 指定ResourceManager的地址-->
      <property>
          <name>yarn.resourcemanager.hostname</name>
          <value>hadoop103</value>
  </property>
  <!-- 环境变量的继承 -->
      <property>
          <name>yarn.nodemanager.env-whitelist</name>
          <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
  </property>
  <!-- yarn容器允许分配的最大最小内存 -->
      <property>
          <name>yarn.scheduler.minimum-allocation-mb</name>
          <value>512</value>
      </property>
      <property>
          <name>yarn.scheduler.maximum-allocation-mb</name>
          <value>4096</value>
  </property>
  <!-- yarn容器允许管理的物理内存大小 -->
      <property>
          <name>yarn.nodemanager.resource.memory-mb</name>
          <value>4096</value>
  </property>
  <!-- 关闭yarn对物理内存和虚拟内存的限制检查 -->
      <property>
          <name>yarn.nodemanager.pmem-check-enabled</name>
          <value>false</value>
      </property>
      <property>
          <name>yarn.nodemanager.vmem-check-enabled</name>
          <value>false</value>
      </property>
  </configuration>
  
  ```

  - mapred-site.xml

  ```xml
  <configuration>
  	<!-- 指定MapReduce程序运行在Yarn上 -->
      <property>
          <name>mapreduce.framework.name</name>
          <value>yarn</value>
      </property>
  </configuration>
  
  ```

- 从102机器发送配置文件

  - 群发脚本

  `xsync.sh hdfs-site.xml core-site.xml yarn-site.xml mapred-site.xml`

## 7. 手动开启服务（了解）

- 102机器上，对hadoop格式化

```properties
hdfs namenode -format
在Hadoop的解压目录下，bin下执行
```

-  hadoop102  : 开启元数据服务namenode，和存储数据服务datanode
   - `hdfs --daemon start namenode`
   - `hdfs --daemon start datanode`

-  hadoop103：开启yarn服务resourceManager，nodenanager,datanode
   - `yarn --daemon start resourcemanager`
   - `yarn --daemon start nodemanager`
   - `hdfs --daemon start datanode`
   - 返回102机器，启动yarn平台`yarn --daemon start nodemanager`
-  hadoop104：开启secondrayname，nodenanager,datanode
   - `hdfs --daemon start secondarynamenode`
   - `hdfs --daemon start datanode`
   - `yarn --daemon start nodemanager`

## 8. 自动服务（群起）

- 服务器群起命令shell代码：`/opt/module/hadoop-3.1.3/sbin`

- 服务器群起修改配置文件：`/opt/module/hadoop-3.1.3/etc/hadoop/workers` ：分发103,104

  ```properties
  hadoop102
  hadoop103
  hadoop104
  ```

- 群起 hdfs：102机器

  - `start-dfs.sh`

- 群起yarn: 103机器

  - `start-yarn.sh`

- 群起群停shell脚本

  - 放在自己的账户目录/bin下（my_hadoop）

  ```shell
  #!/bin/bash
  if [ $# -lt 1 ]
  then
      echo "No Args Input..."
      exit ;
  fi
  case $1 in
  "start")
          echo " =================== 启动 hadoop集群 ==================="
  
          echo " --------------- 启动 hdfs ---------------"
          ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/start-dfs.sh"
          echo " --------------- 启动 yarn ---------------"
          ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/start-yarn.sh"
          echo " --------------- 启动 historyserver ---------------"
          ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver"
  ;;
  "stop")
          echo " =================== 关闭 hadoop集群 ==================="
  
          echo " --------------- 关闭 historyserver ---------------"
          ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver"
          echo " --------------- 关闭 yarn ---------------"
          ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh"
          echo " --------------- 关闭 hdfs ---------------"
          ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh"
  ;;
  *)
      echo "Input Args Error..."
  ;;
  esac
  
  ```

  ## 9. 集群功能测试

`hadoop jar hadoop-mapreduce-examples-3.1.3.jar wordcount /wcinput /wcoutput`











