# 集群练习改错

## 网络故障1

- 查看网络配置文件，修改正确后重启网卡
- 网关与网卡

```bash
sudo vim /etc/sysconfig/network-scripts/ifcfg-ens33 
systemctl restart network
```

## Linux练习1

**做以下操作**

1. **进入/root目录**

2. **新建target文件夹**

3. **进入/opt/software目录**

4. **查看该目录下面的文件**

5. **将目录下面的tar包解压到刚刚新建的target目录**

6. **进入/root/target**

7. **查看刚刚新解压的文件夹**

8. **将刚刚解压的文件夹重命名为zookeeper**

   ```
   mv apache-zookeeper-3.5.7-bin zookeeper
   ```

   

9. **将zookeeper文件夹以及其所有的子文件 所有者和所属组都改为atguigu**

```
chown -R atguigu:atguigu zookeeper/*
```

1.  **进入zookeeper下面的conf目录**
2.  **修改zoo_sample.cfg，将 dataDir=/tmp/zookeeper 这一行修改为 dataDir=/root/target/zookeeper/zkData**
3.  **新建test文件，粘贴bcda，并保存退出**



## Shell练习

编写一个脚本func.sh，实现以下功能

    1.  ‘func.sh jiahe N’，N为整数，返回1+...+N的和
    2.  ‘func.sh jiecheng N’，N为整数，返回N的阶乘
    3.  ‘func.sh xxx N’，xxx为任意字符串，N为整数，输出N行xxx

```bash
[atguigu@hadoop102 bin]$ vim func.sh 
[atguigu@hadoop102 bin]$ cat func.sh 
#!/bin/bash
function jiahe(){
        num=$1
        sum=0
        for((i=1;i<=$num;i++))
        do
        sum=$[$sum+$i]
        done

        echo $sum
}

function jiecheng(){
	num=$1
	sum=1
	for((i=1;i<=$num;i++))
	do
	sum=$[$i*$sum]
	done

	echo $sum
}

function qita(){
	str=$1
	sum=$2
	for((i=1;i<=$sum;i++))
	do
	echo $1
	done
}

case $1 in
"jiahe")
        jiahe $2
;;

"jiecheng")
	jiecheng $2
;;
*)
	qita $1 $2
;;
esac
```

## HDFS1

**HDFS集群无法启动，请分析问题并修复**

- 多次格式化了hdfs中的，要讲cureent文件删除
- 数据需要保存，就去把两个id修改为一致的就行了

```bash
rm -rf /opt/module/hadoop/data/dfs/data/*
```

## 7. 手动开启服务（了解）

- 102机器上，对hadoop格式化

```properties
hdfs namenode -format
在Hadoop的解压目录下，bin下执行
```

-  hadoop102  : 开启元数据服务namenode，和存储数据服务datanode
   - `hdfs --daemon start namenode`
   - `hdfs --daemon start datanode`

-  hadoop103：开启yarn服务resourceManager，nodenanager,datanode
   - `yarn --daemon start resourcemanager`
   - `yarn --daemon start nodemanager`
   - `hdfs --daemon start datanode`
   - 返回102机器，启动yarn平台`yarn --daemon start nodemanager`
-  hadoop104：开启secondrayname，nodenanager,datanode
   - `hdfs --daemon start secondarynamenode`
   - `hdfs --daemon start datanode`
   - `yarn --daemon start nodemanager

-  web端查看HDFS的NameNode

   - ①浏览器中输入：http://hadoop102:9870

   - ②查看HDFS上存储的数据信息

-  （5）Web端查看YARN的ResourceManager

   - ①浏览器中输入：http://hadoop103:8088

   - ②查看YARN上运行的Job信息

-  历史服务器的地址

   - http://hadoop102:19888/jobhistory

## HDFS2

修改用户：所属组

```
xcall 'sudo chown -R atguigu:atguigu /opt/module/*'
```

按照顺序启动就行

## HDFS3

**HDFS命令找不到，请分析问题并修复**

- 环境变量没有配置
- root账户重新加载配置

```
source /etc/profile
```

## HDFS4

- 网页上只能看到一台dn，datanodeuuid三个不能一致

```
uuidgen
```



```bash
tail -n 100 /opt/module/hadoop-3.1.3/logs/hadoop-atguigu-datanode-hadoop102.log
```

- l两个nn与dnID不一致，直接删除current文件夹就行

```bash
rm -rf /opt/module/hadoop/data/dfs/data/current
```

## Yarn错误

- 修改不合理的yarn配置文件

- 服务器群起命令shell代码：`/opt/module/hadoop-3.1.3/sbin`

- 服务器群起修改配置文件：`/opt/module/hadoop-3.1.3/etc/hadoop/workers` ：分发103,104

  ```properties
  hadoop102
  hadoop103
  hadoop104
  ```

- 群起 hdfs：102机器

  - `start-dfs.sh`

- 群起yarn: 103机器

  - `start-yarn.sh`

- 群起群停shell脚本

内存  溢出，文件块小，检查虚拟，实际内存，

任务量多，导致内存溢出，容器被杀掉

开启Uber模式运行

**4）开启uber模式，实现JVM重用。**
		默认情况下，每个Task任务都需要启动一个JVM来运行，如果Task任务计算的数据量很小，我们可以让同一个Job的多个Task运行在一个JVM中，不必为每个Task都开启一个JVM. 
		开启uber模式，在mapred-site.xml中添加如下配置

```xml
<!--  开启uber模式 -->
<property>
	<name>mapreduce.job.ubertask.enable</name>
	<value>true</value>
</property>

<!-- uber模式中最大的mapTask数量，可向下修改  --> 
<property>
	<name>mapreduce.job.ubertask.maxmaps</name>
	<value>9</value>
</property>
<!-- uber模式中最大的reduce数量，可向下修改 -->
<property>
	<name>mapreduce.job.ubertask.maxreduces</name>
	<value>1</value>
</property>
<!-- uber模式中最大的输入数据量，默认使用dfs.blocksize 的值，可向下修改 -->
<property>
	<name>mapreduce.job.ubertask.maxbytes</name>
	<value></value>
</property>
```





